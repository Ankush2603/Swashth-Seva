{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works perfectly for downsizing image can be used for lower res images also but will not bring dimensions to 300x300\n",
    "def downsizingimg(folderpath: str,imgname: str):\n",
    "  img = Image.open(folderpath+imgname)\n",
    "  img.thumbnail((300,300))\n",
    "  img.save(folderpath[:-1]+'_/'+imgname)\n",
    "  m,n = img.size\n",
    "  target_size = (300, 300)\n",
    "  if (m!=300)or(n!=300):\n",
    "    if m>n:\n",
    "      target_size = (m,m)\n",
    "    else:\n",
    "      target_size = (n,n)\n",
    "  else:\n",
    "    return;\n",
    "  image = cv2.imread(folderpath[:-1]+'_/'+imgname)\n",
    "  vertical_padding = (target_size[0] - image.shape[0]) // 2\n",
    "  horizontal_padding = (target_size[1] - image.shape[1]) // 2\n",
    "\n",
    "  padded_image = cv2.copyMakeBorder(image, vertical_padding, vertical_padding, horizontal_padding, horizontal_padding, cv2.BORDER_CONSTANT)\n",
    "  cv2.imwrite(folderpath[:-1]+'_/'+imgname,padded_image)\n",
    "\n",
    "\n",
    "  #brings image dims exactly to 300x300\n",
    "#run after downsizingimg()\n",
    "def resize_image(image_path):\n",
    "    img = load_img(image_path, target_size=(300, 300), color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize pixel values to between 0 and 1\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(300, 300, 1)))\n",
    "  model.add(layers.MaxPooling2D((4, 4)))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "  model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "\n",
    "  model.add(layers.Dense(512, activation='relu'))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(256, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "  model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatapath = \"updated.csv\"\n",
    "cancerpath = \"Brain Tumor_/\"\n",
    "normalpath = \"Healthy_/\"\n",
    "\n",
    "metadata = pd.read_csv(metadatapath)\n",
    "\n",
    "paths=[]\n",
    "labels=[]\n",
    "\n",
    "metadata.drop(metadata.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "for i in range(0,4519):\n",
    "  if (metadata.iloc[i]['class']=='cancer' ):\n",
    "    paths.append(cancerpath+metadata.iloc[i]['Filename'])\n",
    "    labels.append('cancer')\n",
    "  else:\n",
    "    paths.append(normalpath+metadata.iloc[i]['Filename'])\n",
    "    labels.append('normal')\n",
    "df = pd.DataFrame({\n",
    "    'path':paths,\n",
    "    'label':labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=4,\n",
    "    class_mode='binary',  # or 'binary' for binary classification\n",
    "    color_mode='grayscale',  # or 'rgb' for RGB images\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = ModelCheckpoint('model10.h5', save_best_only=True)\n",
    "#history = \n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=val_generator\n",
    "    #callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mod.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
